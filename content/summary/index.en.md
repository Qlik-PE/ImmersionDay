---
title: "Next Steps"
weight: 60
---

### Congratulations! You have completed the workshop

## Clean up:
This workshop utilized Event Engine to provision your AWS Accounts so you do not need to perform any cleanup. The account terminates when the event is over. The workshop requires resources deployed during the session in order to complete; you are unable to run this in your own AWS account.

***Where to go from here?***

In this lab, we demonstrated how to use Qlik Replicate to ingest and data in real-time to your various environments. We learned step-by-step procedure to quickly load sample data from SAP S/4 database into your Amazon Redshift data warehouse. We also observed how data updates happen in real time. Due to cost and timing this lab runs in a single EC2 environment setup with Qlik Replicate and Docker for MySQL, PostgreSQL, Kafka, AWS Aurora, and Single Node Amazon Redshift Cluster.

In case you want learn more about Qlik Replicate, Qlik Data Integration for SAP, Amazon Aurora, Amazon RDS and Amazon Redshift, please visit the following pages:

[Getting started with Qlik Replicate](https://www.qlik.com/us/trial/replicate)

[Qlik Replicate on AWS Marketplace](https://aws.amazon.com/marketplace/pp/prodview-nvvkm6lsly6i4)

[Qlik Data Integration for SAP on AWS Marketplace](https://aws.amazon.com/marketplace/pp/prodview-nfdaa4xh7axt6?sr=0-3&ref_=beagle&applicationId=AWSMPContessa)

[Amazon Aurora](https://aws.amazon.com/rds/aurora/)

[Amazon Relational Database Service](https://aws.amazon.com/rds/)

[Amazon Redshift](https://aws.amazon.com/redshift/)
